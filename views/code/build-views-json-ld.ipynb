{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to build JSON-LD pages that provide multilingual labels and definitions controlled vocabularies\n",
    "# Steve Baskauf 2021-01-08 CC0\n",
    "\n",
    "import re\n",
    "import requests   # best library to manage HTTP transactions\n",
    "import csv        # library to read/write/parse CSV files\n",
    "import json       # library to convert JSON to Python data structures\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------\n",
    "# Configuration section\n",
    "# -----------------\n",
    "\n",
    "# Read in mutable configuration variables\n",
    "with open('config.json', 'rt', encoding='utf-8') as file_object:\n",
    "    config_text = file_object.read()\n",
    "config = json.loads(config_text)\n",
    "\n",
    "# This is the base URL for raw files from the branch of the repo that has been pushed to GitHub. \n",
    "\n",
    "github_base_url = 'https://raw.githubusercontent.com/tdwg/rs.tdwg.org/' + config['branch'] + '/'\n",
    "database_name = config['database_name']\n",
    "\n",
    "translations_url = github_base_url + database_name + '/' + database_name +'-translations.csv'\n",
    "\n",
    "has_broader = config['has_broader'] # set to true in configuration file if any terms have skos:broader values\n",
    "has_exactMatch = config['has_exactMatch'] # set to true of any terms have skos:exactMatch values\n",
    "\n",
    "label_col_prefix = 'label_'\n",
    "def_col_prefix = 'definition_'\n",
    "localname_column_header = 'term_localName'\n",
    "\n",
    "# ---------------\n",
    "# Function definitions\n",
    "# ---------------\n",
    "\n",
    "# replace URL with link\n",
    "#\n",
    "def createLinks(text):\n",
    "    def repl(match):\n",
    "        if match.group(1)[-1] == '.':\n",
    "            return '<a href=\"' + match.group(1)[:-1] + '\">' + match.group(1)[:-1] + '</a>.'\n",
    "        return '<a href=\"' + match.group(1) + '\">' + match.group(1) + '</a>'\n",
    "\n",
    "    pattern = '(https?://[^\\s,;\\)\"]*)'\n",
    "    result = re.sub(pattern, repl, text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv(github_base_url + database_name + '/constants.csv', na_filter=False)\n",
    "namespace_iri = frame.domainRoot[0]\n",
    "\n",
    "translations_frame = pd.read_csv(translations_url, na_filter=False)\n",
    "columns = translations_frame.columns\n",
    "\n",
    "# Extract the list of languages from the translations spreadsheet column headers\n",
    "languages = []\n",
    "for column_header in columns:\n",
    "    if label_col_prefix in column_header:\n",
    "        language_code = column_header.split(label_col_prefix)[1]\n",
    "        if language_code != 'en':\n",
    "            languages.append(column_header.split(label_col_prefix)[1])\n",
    "print(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of language dictionaries for the terms\n",
    "translations_dictionary = {}\n",
    "for index,row in translations_frame.iterrows():\n",
    "    language_dictionary = {}\n",
    "    for language in languages:\n",
    "        term_dictionary = {'label': row[label_col_prefix + language], 'definition': row[def_col_prefix + language]}\n",
    "        language_dictionary[language] = term_dictionary\n",
    "    translations_dictionary[row[localname_column_header]] = language_dictionary\n",
    "print(json.dumps(translations_dictionary, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_info = []\n",
    "frame = pd.read_csv(github_base_url + database_name + '/' + database_name + '.csv', na_filter=False)\n",
    "for index, row in frame.iterrows():\n",
    "    term_dict = {}\n",
    "    term_dict['localname'] = row['term_localName']\n",
    "    term_dict['iri'] = namespace_iri + row['term_localName']\n",
    "    term_dict['label'] = []\n",
    "    term_dict['label'].append({'language': 'en', 'value': row['label']})\n",
    "    for language in languages:\n",
    "        term_dict['label'].append({'language': language, 'value': translations_dictionary[row['term_localName']][language]['label']})\n",
    "    term_dict['definition'] = []\n",
    "    term_dict['definition'].append({'language': 'en', 'value': row['definition']})\n",
    "    for language in languages:\n",
    "        term_dict['definition'].append({'language': language, 'value': translations_dictionary[row['term_localName']][language]['definition']})\n",
    "    term_dict['cv_string'] = row['controlled_value_string']\n",
    "    if row['skos_inScheme'] != '':\n",
    "        term_dict['scheme'] = namespace_iri + row['skos_inScheme']\n",
    "    else:\n",
    "        term_dict['scheme'] = ''\n",
    "    term_dict['type'] = row['type']\n",
    "    if has_broader:\n",
    "        if row['skos_broader'] != '':\n",
    "            term_dict['broader'] = namespace_iri + row['skos_broader']\n",
    "        else:\n",
    "            term_dict['broader'] = ''\n",
    "    if has_exactMatch:\n",
    "        if row['skos_exactMatch'] != '':\n",
    "            term_dict['match'] = namespace_iri + row['skos_exactMatch']\n",
    "        else:\n",
    "            term_dict['match'] = ''\n",
    "    term_dict['value'] = row['controlled_value_string']\n",
    "    term_info.append(term_dict)\n",
    "print(json.dumps(term_info, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dict = {\n",
    "    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "    \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "    \"skos\": \"http://www.w3.org/2004/02/skos/core#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "    \"skos:inScheme\": {\"@type\": \"@id\"}\n",
    "  }\n",
    "\n",
    "if has_broader:\n",
    "    context_dict['skos:broader'] = {\"@type\": \"@id\"}\n",
    "\n",
    "if has_exactMatch:\n",
    "    context_dict['skos:exactMatch'] = {\"@type\": \"@id\"}\n",
    "\n",
    "graph_list = []\n",
    "for term in term_info:\n",
    "    term_dict = {}\n",
    "    term_dict['@id'] = term['iri']\n",
    "    term_dict['@type'] = term['type']\n",
    "    if term['value'] != '':\n",
    "        term_dict['rdf:value'] = term['value']\n",
    "    if term['scheme'] != '':\n",
    "        term_dict['skos:inScheme'] = term['scheme']\n",
    "    if has_broader:\n",
    "        if term['broader'] != '':\n",
    "            term_dict['skos:broader'] = term['broader']\n",
    "    if has_exactMatch:\n",
    "        if term['match'] != '':\n",
    "            term_dict['skos:exactMatch'] = term['match']\n",
    "    label_list = []\n",
    "    for lang_label in term['label']:\n",
    "        label_list.append({'@language': lang_label['language'], '@value': lang_label['value']})\n",
    "    term_dict['skos:prefLabel'] = label_list\n",
    "    \n",
    "    def_list = []\n",
    "    for lang_label in term['definition']:\n",
    "        def_list.append({'@language': lang_label['language'], '@value': lang_label['value']})\n",
    "    term_dict['skos:definition'] = def_list\n",
    "    \n",
    "    graph_list.append(term_dict)\n",
    "\n",
    "output = {\"@context\": context_dict, \"@graph\": graph_list}\n",
    "#jsonld_output = json.dumps(output, indent = 2) # output as escaped characters\n",
    "jsonld_output = json.dumps(output, indent = 2, ensure_ascii=False) # output at UTF-8 strings\n",
    "print(jsonld_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputObject = open(out_filename, 'wt', encoding='utf-8') # use with escaped characters\n",
    "for out_filename in [database_name + '.json', database_name + '.jsonld']:\n",
    "    outputObject = open(out_filename, 'w', encoding='utf-8') # use with UTF-8 strings\n",
    "    outputObject.write(jsonld_output)\n",
    "    outputObject.close()\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the SKOS collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this value to \"part\" for the parts collections and to \"orient\" for orientations collections\n",
    "selection = 'orient'\n",
    "\n",
    "collections = pd.read_csv(selection + '_collections.csv', na_filter=False, dtype = str)\n",
    "join = pd.read_csv('part_collection_join.csv', na_filter=False, dtype = str)\n",
    "concepts = pd.read_csv(github_base_url + database_name + '/' + database_name + '.csv', na_filter=False)\n",
    "\n",
    "#collections.head()\n",
    "#join.head()\n",
    "#concepts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "database_name = 'ac' + selection\n",
    "languages = [] # Multilingual support needs to be added; see the older script which enabled it\n",
    "collection_namespace_iri = 'http://rs.tdwg.org/' + database_name + '/collection/'\n",
    "concept_namespace_iri = 'http://rs.tdwg.org/' + database_name + '/values/'\n",
    "\n",
    "# Simultaneously generate a Markdown document\n",
    "markdown_string = '# Controlled value strings from SKOS Collections for '\n",
    "if selection == 'part':\n",
    "    markdown_string += 'ac:subjectPartLiteral\\n\\n'\n",
    "elif selection == 'orient':\n",
    "    markdown_string += 'ac:subjectOrientationLiteral\\n\\n'\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Extract data from the dataframe\n",
    "term_info = []\n",
    "for index, row in collections.iterrows():\n",
    "    term_dict = {}\n",
    "    term_dict['localname'] = row['term_localName']\n",
    "    term_dict['iri'] = collection_namespace_iri + row['term_localName']\n",
    "    \n",
    "    term_dict['label'] = []\n",
    "    term_dict['label'].append({'language': 'en', 'value': row['label']})\n",
    "    for language in languages:\n",
    "        term_dict['label'].append({'language': language, 'value': translations_dictionary[row['term_localName']][language]['label']})\n",
    "\n",
    "    term_dict['definition'] = []\n",
    "    term_dict['definition'].append({'language': 'en', 'value': row['definition']})\n",
    "    for language in languages:\n",
    "        term_dict['definition'].append({'language': language, 'value': translations_dictionary[row['term_localName']][language]['definition']})\n",
    "        \n",
    "    term_dict['type'] = row['type']\n",
    "    term_info.append(term_dict)\n",
    "    \n",
    "# Start building the Python data structure analogous to the evental output JSON\n",
    "context_dict = {\n",
    "    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "    \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "    \"skos\": \"http://www.w3.org/2004/02/skos/core#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "    \"skos:member\": {\"@type\": \"@id\"}\n",
    "  }\n",
    "\n",
    "if selection == 'orient': # only the orientation collections need to be linked back to part concepts\n",
    "    context_dict['tdwgutility:ofConcept'] = {\"@type\": \"@id\"}\n",
    "\n",
    "graph_list = []\n",
    "for term in term_info:\n",
    "    term_dict = {}\n",
    "    term_dict['@id'] = term['iri']\n",
    "    term_dict['@type'] = term['type']\n",
    "    if selection == 'orient': # only orientation collections need to be linked to a part concept\n",
    "        term_dict['tdwgutility:ofConcept'] = 'http://rs.tdwg.org/acpart/values/' + term['localname']\n",
    "    \n",
    "    label_list = []\n",
    "    for lang_label in term['label']:\n",
    "        label_list.append({'@language': lang_label['language'], '@value': lang_label['value']})\n",
    "\n",
    "        # Add to Markdown doc\n",
    "        if lang_label['language'] == 'en':\n",
    "            markdown_string += '## ' + lang_label['value'] + '\\n<ul>\\n'\n",
    "            #print(lang_label['value'])\n",
    "        \n",
    "    term_dict['skos:prefLabel'] = label_list\n",
    "        \n",
    "    def_list = []\n",
    "    for lang_label in term['definition']:\n",
    "        def_list.append({'@language': lang_label['language'], '@value': lang_label['value']})\n",
    "    term_dict['skos:definition'] = def_list\n",
    "    \n",
    "    # Add the members of the collection\n",
    "    members_list = []\n",
    "    for index, row in join.iterrows():\n",
    "        if row['collection_id'] == term['localname']:\n",
    "            members_list.append(concept_namespace_iri + row['member_id'])\n",
    "            \n",
    "            # Add to Markdown doc: look up the CV string in the concepts dataframe\n",
    "            cv_string = concepts.loc[concepts.term_localName == row['member_id'], 'controlled_value_string'].values[0]\n",
    "            markdown_string += '<li>' + cv_string + '</li>\\n'\n",
    "            \n",
    "    term_dict['skos:member'] = members_list\n",
    "    \n",
    "    # Add to Markdown doc\n",
    "    markdown_string += '</ul>\\n\\n'\n",
    "    \n",
    "    graph_list.append(term_dict)\n",
    "\n",
    "output = {\"@context\": context_dict, \"@graph\": graph_list}\n",
    "\n",
    "jsonld_output = json.dumps(output, indent = 2, ensure_ascii=False) # output at UTF-8 strings\n",
    "print(jsonld_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out_filename in [database_name + '_collection.json', database_name + '_collection.jsonld']:\n",
    "    outputObject = open(out_filename, 'w', encoding='utf-8') # use with UTF-8 strings\n",
    "    outputObject.write(jsonld_output)\n",
    "    outputObject.close()\n",
    "    \n",
    "with open(selection + '_collections.md', 'wt', encoding='utf-8') as fileObject:\n",
    "    fileObject.write(markdown_string)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
