{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to build JSON-LD pages that provide multilingual labels and definitions controlled vocabularies\n",
    "# Steve Baskauf 2021-01-08 CC0\n",
    "\n",
    "import re\n",
    "import requests   # best library to manage HTTP transactions\n",
    "import csv        # library to read/write/parse CSV files\n",
    "import json       # library to convert JSON to Python data structures\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------\n",
    "# Configuration section\n",
    "# -----------------\n",
    "\n",
    "# This is the base URL for raw files from the branch of the repo that has been pushed to GitHub. In this example,\n",
    "# the branch is named \"pathway\"\n",
    "github_base_url = 'https://raw.githubusercontent.com/tdwg/ac/master/views/code/'\n",
    "\n",
    "\n",
    "has_broader = True # set to true if any terms have skos:broader values\n",
    "has_exactMatch = False # set to true of any terms have skos:exactMatch values\n",
    "\n",
    "label_col_prefix = 'label_'\n",
    "def_col_prefix = 'definition_'\n",
    "localname_column_header = 'term_localName'\n",
    "\n",
    "namespace_iri = 'http://rs.tdwg.org/acviews/values/'\n",
    "collections_namespace = 'http://rs.tdwg.org/acviews/collections/'\n",
    "\n",
    "# ---------------\n",
    "# Function definitions\n",
    "# ---------------\n",
    "\n",
    "# main function\n",
    "#\n",
    "def create_cv(database_name):\n",
    "    translations_url = github_base_url + database_name + '-translations.csv'\n",
    "    translations_frame = pd.read_csv(translations_url, na_filter=False)\n",
    "    columns = translations_frame.columns\n",
    "\n",
    "    # Extract the list of languages from the translations spreadsheet column headers\n",
    "    languages = []\n",
    "    for column_header in columns:\n",
    "        if label_col_prefix in column_header:\n",
    "            language_code = column_header.split(label_col_prefix)[1]\n",
    "            if language_code != 'en':\n",
    "                languages.append(column_header.split(label_col_prefix)[1])\n",
    "    #print(languages)\n",
    "    \n",
    "    # Create a dictionary of language dictionaries for the terms\n",
    "    translations_dictionary = {}\n",
    "    for index,row in translations_frame.iterrows():\n",
    "        language_dictionary = {}\n",
    "        for language in languages:\n",
    "            term_dictionary = {'label': row[label_col_prefix + language], 'definition': row[def_col_prefix + language]}\n",
    "            language_dictionary[language] = term_dictionary\n",
    "        translations_dictionary[row[localname_column_header]] = language_dictionary\n",
    "    #print(json.dumps(translations_dictionary, indent = 2))\n",
    "    \n",
    "    # Create a list of term info dictionaries\n",
    "    term_info = []\n",
    "    term_dict = {}\n",
    "    frame = pd.read_csv(github_base_url + database_name + '.csv', na_filter=False)\n",
    "    for index,row in frame.iterrows():\n",
    "        term_dict = {}\n",
    "        term_dict['localname'] = row['term_localName']\n",
    "        term_dict['iri'] = namespace_iri + row['term_localName']\n",
    "        term_dict['label'] = []\n",
    "        term_dict['label'].append({'language': 'en', 'value': row['label']})\n",
    "        for language in languages:\n",
    "            term_dict['label'].append({'language': language, 'value': translations_dictionary[row['term_localName']][language]['label']})\n",
    "        term_dict['definition'] = []\n",
    "        term_dict['definition'].append({'language': 'en', 'value': row['definition']})\n",
    "        for language in languages:\n",
    "            term_dict['definition'].append({'language': language, 'value': translations_dictionary[row['term_localName']][language]['definition']})\n",
    "        term_dict['cv_string'] = row['controlled_value_string']\n",
    "        if row['skos_inScheme'] != '':\n",
    "            term_dict['scheme'] = namespace_iri + row['skos_inScheme']\n",
    "        else:\n",
    "            term_dict['scheme'] = ''\n",
    "        term_dict['type'] = row['type']\n",
    "        if has_broader:\n",
    "            if row['skos_broader'] != '':\n",
    "                term_dict['broader'] = namespace_iri + row['skos_broader']\n",
    "            else:\n",
    "                term_dict['broader'] = ''\n",
    "        if has_exactMatch:\n",
    "            if row['skos_exactMatch'] != '':\n",
    "                term_dict['match'] = namespace_iri + row['skos_exactMatch']\n",
    "            else:\n",
    "                term_dict['match'] = ''\n",
    "        term_dict['value'] = row['controlled_value_string']\n",
    "        term_info.append(term_dict)\n",
    "    #print(json.dumps(term_info, indent = 2))\n",
    "\n",
    "    # Generate the JSON-LD for the terms\n",
    "    context_dict = {\n",
    "        \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "        \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "        \"skos\": \"http://www.w3.org/2004/02/skos/core#\",\n",
    "        \"xsd\": \"http://www.w3.org/2001/XMLSchema#\"\n",
    "      }\n",
    "\n",
    "    graph_list = []\n",
    "    for term in term_info:\n",
    "        term_dict = {}\n",
    "        term_dict['@id'] = term['iri']\n",
    "        term_dict['@type'] = term['type']\n",
    "        if term['value'] != '':\n",
    "            term_dict['rdf:value'] = term['value']\n",
    "        if term['scheme'] != '':\n",
    "            term_dict['skos:inScheme'] = term['scheme']\n",
    "        if has_broader:\n",
    "            if term['broader'] != '':\n",
    "                term_dict['skos:broader'] = term['broader']\n",
    "        if has_exactMatch:\n",
    "            if term['match'] != '':\n",
    "                term_dict['skos:exactMatch'] = term['match']\n",
    "        label_list = []\n",
    "        for lang_label in term['label']:\n",
    "            label_list.append({'@language': lang_label['language'], '@value': lang_label['value']})\n",
    "        term_dict['skos:prefLabel'] = label_list\n",
    "\n",
    "        def_list = []\n",
    "        for lang_label in term['definition']:\n",
    "            def_list.append({'@language': lang_label['language'], '@value': lang_label['value']})\n",
    "        term_dict['skos:definition'] = def_list\n",
    "\n",
    "        graph_list.append(term_dict)\n",
    "\n",
    "    output = {\"@context\": context_dict, \"@graph\": graph_list}\n",
    "    #jsonld_output = json.dumps(output, indent = 2) # output as escaped characters\n",
    "    jsonld_output = json.dumps(output, indent = 2, ensure_ascii=False) # output at UTF-8 strings\n",
    "    #print(jsonld_output)\n",
    "    \n",
    "    # outputObject = open(out_filename, 'wt', encoding='utf-8') # use with escaped characters\n",
    "    for out_filename in [database_name + '.json', database_name + '.jsonld']:\n",
    "        outputObject = open(out_filename, 'w', encoding='utf-8') # use with UTF-8 strings\n",
    "        outputObject.write(jsonld_output)\n",
    "        outputObject.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_names = ['subjectOrientation', 'subjectPart']\n",
    "for database_name in database_names:\n",
    "    create_cv(database_name)\n",
    "    print('Created', database_name + '.json')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'part_collection_join'\n",
    "\n",
    "# Create the context dictionary\n",
    "context_dict = {\n",
    "    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "    \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "    \"skos\": \"http://www.w3.org/2004/02/skos/core#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\"\n",
    "  }\n",
    "\n",
    "# Load the data about the collections\n",
    "frame = pd.read_csv(github_base_url + 'skos_collections.csv', na_filter=False)\n",
    "collection_list = []\n",
    "for index,term in frame.iterrows():\n",
    "    term_dict = {}\n",
    "    term_dict['@id'] = term['term_localName']\n",
    "    term_dict['skos:prefLabel'] = [{'@language': 'en', '@value': term['label']}]\n",
    "    # ** Need to fix this to add multilingual labels\n",
    "    # term_dict['skos:prefLabel'] = {'@language': lang_label['language'], '@value': lang_label['value']}\n",
    "    collection_list.append(term_dict)\n",
    "\n",
    "# create list of collections descriptions\n",
    "collections_info = []\n",
    "\n",
    "frame = pd.read_csv(github_base_url + database_name + '.csv', na_filter=False)\n",
    "\n",
    "# create the lists of members\n",
    "for collection in collection_list:\n",
    "    collection_dict = {'@id': collections_namespace + collection['@id']}\n",
    "    collection_dict['@type'] = 'http://www.w3.org/2004/02/skos/core#Collection'\n",
    "    collection_dict['skos:prefLabel'] = collection['skos:prefLabel']\n",
    "    values_list = []\n",
    "\n",
    "    for index,term in frame.iterrows():\n",
    "        if collection['@id'] == term['collection_id']:\n",
    "            values_list.append(namespace_iri + term['member_id'])\n",
    "    if len(values_list) != 0:\n",
    "        collection_dict['skos:member'] = values_list\n",
    "        collections_info.append(collection_dict)\n",
    "\n",
    "output = {\"@context\": context_dict, \"@graph\": collections_info}\n",
    "#jsonld_output = json.dumps(output, indent = 2) # output as escaped characters\n",
    "jsonld_output = json.dumps(output, indent = 2, ensure_ascii=False) # output at UTF-8 strings\n",
    "\n",
    "#print(jsonld_output)\n",
    "filename = 'views_collections'\n",
    "for out_filename in [filename + '.json', filename + '.jsonld']:\n",
    "    outputObject = open(out_filename, 'w', encoding='utf-8') # use with UTF-8 strings\n",
    "    outputObject.write(jsonld_output)\n",
    "    outputObject.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
